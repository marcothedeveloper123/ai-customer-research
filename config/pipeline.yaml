# Data Processing Pipeline Configuration

# Pipeline settings
pipeline:
  name: "customer_research_analysis"
  version: "1.0.0"
  description: "AI-powered customer research analysis pipeline"

# Data loading configuration
data_loading:
  supported_formats:
    - csv
    - json
    - txt
    - xlsx

  csv:
    encoding: utf-8
    delimiter: ","
    skip_rows: 0
    header_row: 0

  json:
    encoding: utf-8
    json_lines: false

  txt:
    encoding: utf-8
    line_separator: "\n"

# Text preprocessing
preprocessing:
  enabled: true

  cleaning:
    remove_html: true
    remove_urls: true
    remove_emails: true
    remove_special_chars: false
    lowercase: false
    remove_extra_whitespace: true

  normalization:
    unicode_normalize: true
    normalize_quotes: true
    normalize_dashes: true

  filtering:
    min_length: 10          # Minimum text length in characters
    max_length: 10000       # Maximum text length
    remove_duplicates: true
    remove_empty: true

# Analysis configuration
analysis:
  tasks:
    - sentiment_analysis
    - theme_extraction
    - insight_generation

  sentiment_analysis:
    enabled: true
    model: llama2
    output_format: "categorical"  # categorical | score | both
    categories:
      - positive
      - neutral
      - negative
    confidence_threshold: 0.7

  theme_extraction:
    enabled: true
    model: llama2
    max_themes: 10
    min_frequency: 2
    clustering: auto

  insight_generation:
    enabled: true
    model: llama2
    max_insights: 20
    insight_types:
      - patterns
      - trends
      - anomalies
      - recommendations

# Output configuration
output:
  format: json              # json | csv | markdown
  save_intermediate: true   # Save intermediate results

  paths:
    results: "data/output/analysis_results.json"
    intermediate: "data/processed/"
    reports: "data/output/reports/"
    visualizations: "data/output/visualizations/"

  reporting:
    include_summary: true
    include_details: true
    include_visualizations: false
    include_raw_data: false

# Batch processing
batch_processing:
  enabled: true
  batch_size: 10
  parallel_batches: 3
  progress_reporting: true

# Logging
logging:
  level: INFO               # DEBUG | INFO | WARNING | ERROR
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  output:
    - console
    - file
  file_path: "logs/pipeline.log"
  rotation: "100 MB"

# Performance
performance:
  cache_results: true
  cache_ttl: 3600
  timeout: 300              # seconds
  memory_limit: "2GB"
